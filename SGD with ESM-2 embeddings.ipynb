{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14875579,"sourceType":"competition"},{"sourceId":14141413,"sourceType":"datasetVersion","datasetId":9012019}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stochastic Gradient Descent with ESM-2 embeddings\n\nIdea:\n- Model: OneVsRestClassifier(SGDClassifier) --> train one Logistic Regression model for one class\n- Features: PCA(n_components=100) --> PCA.fit_transform(ESM-2 embeddings)\n- Labels: Three sets for three ontologies (P, C, F)\n    - P has 16858 classes\n    - C has 2651 classes\n    - F has 6616 classes\n\nReferences:\n- (EDA + OneVsRestClassifier) https://www.kaggle.com/code/analyticaobscura/cafa-6-decoding-protein-mysteries\n- (ESM-2 320-D embeddings) https://www.kaggle.com/code/dalloliogm/compute-protein-embeddings-with-esm2-esm-c/notebook\n- (Optional ProtT5 1024-D embeddings) https://www.kaggle.com/code/ahsuna123/t5-embedding-calculation-cafa-6/output?select=train_ids.npy\n\n---","metadata":{}},{"cell_type":"code","source":"!pip install biopython > /dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:43.423206Z","iopub.execute_input":"2025-12-15T08:30:43.423430Z","iopub.status.idle":"2025-12-15T08:30:50.545752Z","shell.execute_reply.started":"2025-12-15T08:30:43.423399Z","shell.execute_reply":"2025-12-15T08:30:50.544753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 1: Load CAFA6 files\n\n---","metadata":{}},{"cell_type":"code","source":"# CAFA6 file paths\nTRAIN_TERMS = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\nTRAIN_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\"\nTEST_SEQ = \"/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:50.548019Z","iopub.execute_input":"2025-12-15T08:30:50.548252Z","iopub.status.idle":"2025-12-15T08:30:50.552463Z","shell.execute_reply.started":"2025-12-15T08:30:50.548229Z","shell.execute_reply":"2025-12-15T08:30:50.551729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from Bio import SeqIO \n\n# Dict {entryId, seq}\ntrain_sequences = {rec.id: str(rec.seq) for rec in SeqIO.parse(TRAIN_SEQ, 'fasta')}\ntest_sequences  = {rec.id: str(rec.seq) for rec in SeqIO.parse(TEST_SEQ,  'fasta')}\n\nprint(f'Loaded {len(train_sequences)} train and {len(test_sequences)} test sequences')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:50.553189Z","iopub.execute_input":"2025-12-15T08:30:50.553402Z","iopub.status.idle":"2025-12-15T08:30:53.536430Z","shell.execute_reply.started":"2025-12-15T08:30:50.553382Z","shell.execute_reply":"2025-12-15T08:30:53.535775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train dict:\", list(train_sequences.items())[0])\nprint(\"Test dict:\", list(test_sequences.items())[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:53.537129Z","iopub.execute_input":"2025-12-15T08:30:53.537374Z","iopub.status.idle":"2025-12-15T08:30:53.602150Z","shell.execute_reply.started":"2025-12-15T08:30:53.537354Z","shell.execute_reply":"2025-12-15T08:30:53.601512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ids = [i.split('|')[1] for i in train_sequences.keys()]\ntest_ids = list(test_sequences.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:53.602819Z","iopub.execute_input":"2025-12-15T08:30:53.603046Z","iopub.status.idle":"2025-12-15T08:30:53.639077Z","shell.execute_reply.started":"2025-12-15T08:30:53.603029Z","shell.execute_reply":"2025-12-15T08:30:53.638424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"train_ids[0:10]:\", train_ids[0:10])\nprint(\"test_ids[0:10]:\", test_ids[0:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:53.639776Z","iopub.execute_input":"2025-12-15T08:30:53.639990Z","iopub.status.idle":"2025-12-15T08:30:53.654637Z","shell.execute_reply.started":"2025-12-15T08:30:53.639974Z","shell.execute_reply":"2025-12-15T08:30:53.653906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Feature extraction\n\n---","metadata":{}},{"cell_type":"code","source":"# Embeddings file paths\nESM_EMBEDDINGS = \"/kaggle/input/cafa6-esm2-650m-embedding/esm2_650M\"\nTRAIN_EMBEDDINGS = ESM_EMBEDDINGS + \"/train_sequences_emb.npy\"\nTEST_EMBEDDINGS = ESM_EMBEDDINGS + \"/testsuperset_emb.npy\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:53.656398Z","iopub.execute_input":"2025-12-15T08:30:53.656634Z","iopub.status.idle":"2025-12-15T08:30:53.669836Z","shell.execute_reply.started":"2025-12-15T08:30:53.656618Z","shell.execute_reply":"2025-12-15T08:30:53.669159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Load embeddings\nX_train = np.load(TRAIN_EMBEDDINGS)\nX_test = np.load(TEST_EMBEDDINGS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:53.670553Z","iopub.execute_input":"2025-12-15T08:30:53.670757Z","iopub.status.idle":"2025-12-15T08:30:59.894134Z","shell.execute_reply.started":"2025-12-15T08:30:53.670742Z","shell.execute_reply":"2025-12-15T08:30:59.893573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:59.894938Z","iopub.execute_input":"2025-12-15T08:30:59.895258Z","iopub.status.idle":"2025-12-15T08:30:59.899368Z","shell.execute_reply.started":"2025-12-15T08:30:59.895234Z","shell.execute_reply":"2025-12-15T08:30:59.898655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=100, random_state=42)\nX_train_reduced = pca.fit_transform(X_train)\nX_test_reduced  = pca.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:30:59.900100Z","iopub.execute_input":"2025-12-15T08:30:59.900350Z","iopub.status.idle":"2025-12-15T08:31:12.422353Z","shell.execute_reply.started":"2025-12-15T08:30:59.900325Z","shell.execute_reply":"2025-12-15T08:31:12.421567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train_reduced shape:\", X_train_reduced.shape)\nprint(\"X_test_reduced shape:\", X_test_reduced.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:31:12.423212Z","iopub.execute_input":"2025-12-15T08:31:12.423699Z","iopub.status.idle":"2025-12-15T08:31:12.427870Z","shell.execute_reply.started":"2025-12-15T08:31:12.423675Z","shell.execute_reply":"2025-12-15T08:31:12.427085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Label encoding and Training\n\n---","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom tqdm import tqdm\n\nmlb_dict = dict()\nmodels = dict()\n\ntrain_terms_df = pd.read_csv(TRAIN_TERMS, sep=\"\\t\")\n\nfor aspect in tqdm(['P', 'C', 'F'], desc=\"Training models\"):\n    # Filter the train_terms_df based on aspect\n    ont_terms_df = train_terms_df[train_terms_df['aspect'] == aspect]\n\n    # Group the dataFrame based on the EntryID, turn all the GO terms to a list, finally turns this dataFrame to a dict {entryID: terms}\n    protein_terms = ont_terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n\n    # Create a list of labels for this aspect, if an entryID doesn't exist in this aspect, give it a []\n    # This ensures y_train is of shape (82404, ...)\n    labels = [protein_terms.get(entry_id, []) for entry_id in train_ids]\n\n    # Multi-hot encoding, use sparse representation\n    mlb = MultiLabelBinarizer(sparse_output=True)\n    y_train = mlb.fit_transform(labels)\n    \n    print(f\"y_train shape for {aspect} ontology: {y_train.shape} \\t Number of unique {aspect} terms: {y_train.shape[1]}\")\n\n    # Save to dict\n    mlb_dict[aspect] = mlb\n    model = OneVsRestClassifier(\n        SGDClassifier(\n            loss='log_loss',\n            alpha=1e-4,\n            max_iter=1000,\n            tol=1e-3,\n            n_jobs=-1,\n            random_state=42\n        ),\n        n_jobs=-1\n    )\n    model.fit(X_train_reduced, y_train)\n    models[aspect] = model\n    print(f\"Model for {aspect} trained successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:35:10.532344Z","iopub.execute_input":"2025-12-15T08:35:10.533179Z","iopub.status.idle":"2025-12-15T08:35:21.989838Z","shell.execute_reply.started":"2025-12-15T08:35:10.533152Z","shell.execute_reply":"2025-12-15T08:35:21.988835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Inference and Submission","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 5000  # avoid memory overflow\nsubmission_list = []\n\nfor i in tqdm(range(0, len(test_ids), BATCH_SIZE), desc=\"Predicting on Test Set\"):\n    batch_entry_ids = test_ids[i : i + BATCH_SIZE]\n\n    X_batch = X_test_reduced[i : i + BATCH_SIZE]\n\n    for aspect, model in models.items():\n        mlb = mlb_dict[aspect]\n        y_pred_proba = model.predict_proba(X_batch)\n\n        for j, entry_id in enumerate(batch_entry_ids):\n            probs = y_pred_proba[j]\n            candidate_indices = np.where(probs > 0.02)[0]\n\n            for idx in candidate_indices:\n                submission_list.append((entry_id, mlb.classes_[idx], round(probs[idx], 3)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:31:14.341848Z","iopub.status.idle":"2025-12-15T08:31:14.342072Z","shell.execute_reply.started":"2025-12-15T08:31:14.341965Z","shell.execute_reply":"2025-12-15T08:31:14.341974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.DataFrame(submission_list, columns=['Protein Id', 'GO Term Id', 'Prediction'])\nsubmission_df.to_csv('submission_no_limit.tsv', sep='\\t', index=False, header=False)\n\nprint(\"Applying 1500 prediction limit per protein...\")\nsubmission_df = submission_df.sort_values(by=['Protein Id', 'Prediction'], ascending=[True, False])\nfinal_submission_df = submission_df.groupby('Protein Id').head(1500).reset_index(drop=True)\nfinal_submission_df.to_csv('submission.tsv', sep='\\t', index=False, header=False)\n\nprint(\"\\nSubmission file 'submission.tsv' created successfully.\")\nprint(f\"Total predictions in final submission: {len(final_submission_df):,}\")\nprint(\"Submission DataFrame Head:\")\ndisplay(final_submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:31:14.343055Z","iopub.status.idle":"2025-12-15T08:31:14.343376Z","shell.execute_reply.started":"2025-12-15T08:31:14.343202Z","shell.execute_reply":"2025-12-15T08:31:14.343220Z"}},"outputs":[],"execution_count":null}]}